<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html lang="en"><head><meta charset="UTF-8" /><meta content="width=device-width, initial-scale=1" name="viewport" /><link href="/Stylesheets/mainLayout.css" rel="stylesheet" /><link crossorigin="anonymous" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" rel="stylesheet" /><script crossorigin="anonymous" src="https://kit.fontawesome.com/4d394c7085.js"></script><link href="Images/Favicon/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180" /><link href="Images/Favicon/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png" /><link href="Images/Favicon/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png" /><link href="Images/Favicon/site.webmanifest" rel="manifest" /><link color="#ffe986" href="Images/Favicon/safari-pinned-tab.svg" rel="mask-icon" /><link href="Images/Favicon/favicon.ico" rel="shortcut icon" /><meta content="#da532c" name="msapplication-TileColor" /><meta content="Images/Favicon/browserconfig.xml" name="msapplication-config" /><meta content="#ff5353" name="theme-color" /><title>Jonathan Giezendanner</title><meta content="Jonathan Giezendanner" name="twitter:title" /><meta content="Jonathan Giezendanner" name="twitter:site" /><meta content="website" prefix="og: http://ogp.me/ns#" property="og:type" /><meta content="summary" name="twitter:card" /><meta content="Welcome to the personal website of Jonathan Giezendanner" name="description" /><meta content="Welcome to the personal website of Jonathan Giezendanner" name="twitter:description" /><meta content="https://www.jgiezendanner.com/Images/Profile.png" prefix="og: http://ogp.me/ns#" property="og:image" /><meta content="https://www.jgiezendanner.com/Images/Profile.png" name="twitter:image" /><link href="/Stylesheets/index.css" rel="stylesheet" /></head><body><div id="aboutMe"></div><div class="headerImage"><div class="column"><div class="profileTitle">Dr. Jonathan <b>Giezendanner</b><br />PhD, Engineer</div></div></div><div class="index"><div class="column"><div class="profileImage"><img src="./Images/Profile.png" /></div><div class="headerIcons"><div id="navigation"><nav><a href="#aboutMe"><i class="fa-solid fa-user"></i> About me</a><a href="#science"><i class="fa-solid fa-rocket"></i> Science</a><a href="#gameDev"><i class="fa-solid fa-gamepad"></i> Game Dev</a></nav></div><div class="social"><nav><a class="icon icon-linkedin" href="https://www.linkedin.com/in/j-giezendanner/" rel="noopener noreferrer" target="_blank"></a><a class="icon icon-github" href="https://github.com/GieziJo" rel="noopener noreferrer" target="_blank"></a><a class="icon icon-scholar" href="https://scholar.google.ch/citations?user=cNxEnK4AAAAJ" rel="noopener noreferrer" target="_blank"></a><a class="icon icon-twitter" href="https://twitter.com/JoGiezi" rel="noopener noreferrer" target="_blank"></a><a class="icon icon-mastodon" href="https://sigmoid.social/@JoGiezi" rel="me" target="_blank"></a></nav></div></div><div class="contentSection"><div class="intro" id="aboutMeIntro">Passionate about the natural environment, machine learning and remote sensing, my principal focus is on <b class="highlightText">Deep Learning</b> using <b class="highlightText">Remote Sensing</b> applied to <b class="highlightText">Flood Mapping</b> and other environmental and societal challenges.<br /><br />Interested in technology, I am proficient in multiple programming languages (e.g. c#, Python, javascript) and frameworks, such as <a href="https://www.fast.ai/">fast.ai</a>, <a href="https://pytorch.org/">PyTorch</a>, and <a href="https://code.earthengine.google.com/">Google Earth Engine</a>, as well as <a href="https://www.docker.com/">Docker</a> for deployment and HPCs for model training.<br /><br />Currently Postdoctoral Research Associate at the <a href="https://www.arizona.edu/" rel="noopener noreferrer" target="_blank">University of Arizona</a> in the <a href="https://beth-tellman.github.io/" rel="noopener noreferrer" target="_blank">Social [Pixel] Lab</a> led by Prof. E. Tellman Sullivan in Tucson.<br /><a class="LearnMoreLink" href="#science">➞ My research</a><br /><br />As a passion project, I co-founded the company <a href="https://earlycoffee.games/" rel="noopener noreferrer" target="_blank">Early Coffee Games</a> where I am the lead developer.<br /><a class="LearnMoreLink" href="#gameDev">➞ My Game Dev Studio</a><br /><br /><br /><a href="CV_Giezendanner.pdf" id="fullCV" rel="noopener noreferrer" target="_blank"><i class="fa-solid fa-file"></i> Full CV</a></div></div></div><div id="background"><div class="column"><div class="contentSection"><h1>About Me</h1>With a background in <b>Environmental and Computational Engineering and Sciences</b>, from the <a href="https://epfl.ch/en" rel="noopener noreferrer" target="_blank">Swiss Federal Institute of Technology Lausanne</a>, I had an education which allowed me to marry modeling with environmental problems and its applications.<br /><br />My PhD in theoretical ecology at the <a href="https://www.epfl.ch/labs/echo/">Laboratory of Ecohydrology</a> led by Prof. A. Rinaldo, allowed me to get a deep understanding in mathematical modelling applied to process based models, all while furthering my knowledge in probabilities, statistics, and machine learning models.<br /><br />Currently working in the <a href="https://beth-tellman.github.io/" rel="noopener noreferrer" target="_blank">Social [Pixel] Lab</a> led by Prof. E. Tellman Sullivan at the <a href="https://www.arizona.edu/">University of Arizona</a>, I am expanding my understanding of <b>Deep Learning</b> methods applied to floods and other challenging problems linked to the environment and its impact on society.<br /><br />In my spare time, I co-founded the company <a href="https://earlycoffee.games/" rel="noopener noreferrer" target="_blank">Early Coffee Games</a> with a good friend of mine. We have been active in the game development scene for about 10 years, and are currently developing our first commercial game, <a href="https://Underwatertale.com">Hermit: an Underwater Tale</a>. The game has received several grants for its development and promotion.<br /><br />In my free time, I enjoy mountaineering, skiing (when I'm not living in the desert), road and mountain biking, board and video games, movies, music (especially music festivals, I used to organise one), and last but not least, cheese, coffee and beer.</div></div></div><div id="science"><div class="column"><div class="contentSection"><h1>Science</h1><div class="intro">The common theme throughout my work has been mathematical modelling of environmental challenges, be it as it currently is flood mapping with deep learning, or previously process based models of population dynamics.<br /><br />In both my current and past work, optimisation and inference have played a major role.<br /><br />Presented here are chosen topics of my current and past work (wip).</div></div></div></div><div id="scienceCurrent"><div class="column"><div class="contentSection"><h2>Current Work</h2>My current work focuses on developing novel Deep Learning solutions to Remote Sensing products in order to address environmental and societal challenges, mainly, but not exclusively, flood mapping.<br /><br />Presented here is my main work on flood mapping.<br /><br /></div></div><div id="NIP"><div class="column"><div class="contentSection"><div class="scienceWorkContent"><h3>Historical Mapping of Bangladesh Floods - MODIS / Sentinel-1 DL Fusion</h3><div class="scienceCollaborators">Collaborators: <a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/rohitmukherjee/'>Rohit Mukherjee</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/matthew-purri/'>Matthew Purri</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/mitchell-thomas-4a8087179/'>Mitchell Thomas</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/max-mauerman-76713b9b'>Max Mauerman</a><a target='_blank'  rel='noopener noreferrer' href='http://www.columbia.edu/~ula2/'>Upmanu Lall</a><a target='_blank'  rel='noopener noreferrer' href='http://www.ffwc.gov.bd/index.php/about-us/professionals'>Arifuzzaman Bhuyan</a><a target='_blank'  rel='noopener noreferrer' href='https://akmsaifulislam.buet.ac.bd/'>A.K.M. Saiful Islam</a><a target='_blank'  rel='noopener noreferrer' href='https://beth-tellman.github.io/'>Beth Tellman</a></div>Economic impacts of floods push people into poverty and cause setbacks to development as government budgets are stretched and people without financial protection are forced to sell assets.<br /><br />Accurate return period estimates of flood events are paramount to develop robust insurance products.<br /><br />We here apply a deep learning algorithm (combined Long-Short-Term-Memory (LSTM) and Convolutional Neural Network (CNNs)) approach.<br /><br /><details><summary><div class="summary"><div class="summaryImage"><img src="./Images/Science/NIP/BangladeshFloodMap.jpg" /></div></div><div class="summaryText">Click to Read On<br /><pre>↓ </pre></div></summary><div><br /><br />By combining historical MODIS satellite images with modern Sentinel-1 images, we produce reliable return period estimates.<br /><br /><div class="ScienceInsert" id="NIPModelImg"><a href="./Images/Science/NIP/FrameworkSchemaModel.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/FrameworkSchemaModel.png" /></a><span>Schematic representation of the proposed framework. Based on a Sentinel-1 derived flood map, aggregated at 500 meter resolution, we train a fusion model which infers the fraction of flooded area in each pixel based on MODIS features.</span></div><br />The proposed framework takes advantage of the ability of radar to "see" water even through clouds, one of the major challenges of flood mapping.<div class="ScienceInsert rightInsert" id="NIModel"><a href="./Images/Science/NIP/modelSchema.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/modelSchema.png" /></a><span>Details of Fusion model consisting in a series of Convolutional Neural Networks (CNNs) applied to MODIS 8-days composite images, passed through a Long Short Term Memory (LSTM) network, and later merged with the MODIS image at time t, to finally go through a last CNN.</span></div><br /><br />By crating a model able to fuse MODIS 8-days  composite images with Sentinel-1 derived fraction of flooded area, we infer a 20 years long historical time series over Bangladesh based on the 20 years long MODIS time series.<br /><br />The data to train, test and validate the model is comprised of every 32x32 500 meters resolution chip where MODIS 8days composite and Sentinel-1 fully overlap. Sentinel-1 is available since 2017.<br /><br />The proposed model takes advantage of both the spatial and temporal information contained in MODIS images.<br /><br />For each time step, the n previous time steps are considered to make a prediction on the fraction of flooded area, leveraging the temporal dynamics of floods.<br /><br />Each image first goes through a <a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener noreferrer" target="_blank">Convolutional Neural Network (CNN)</a>, extracting the spatial information and compiling the multi bands information into a single value for each pixel.<br /><br />This generates a series of values for each pixel, which is then passed through a <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener noreferrer" target="_blank">Long Short Term Memory (LSTM)</a> network designed to, through a series of gates, predict the probability of flood to be present.<br /><br />Finally, the output of the LSTM is combined with the MODIS composite image at time t and passed through a final CNN, generating a prediction for the fraction of flooded area for each pixel in the image.<br /><br /><div class="NIPResultGrid" id="NIPResult"><div class="ScienceInsert" id="NIPMappedImg"><a href="./Images/Science/NIP/Mapped.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/Mapped.png" /></a><span>Observed and Inferred fraction of flooded area, result of deep learning fusion between MODIS and derived Sentinel-1 data, along with error (difference) and MODIS False Color Composite (FCC), for a chosen date selected out of the testing Set (Mai. 5 2020).</span></div><div class="ScienceInsert" id="NIPErrorImg"><a href="./Images/Science/NIP/ErrorDistribution.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/ErrorDistribution.png" /></a><span>Error distribution between the observation (Sentinel-1 algorithm) and Model for the full testing set.</span></div></div><br /><div class="ScienceInsert leftInsert" id="NIPTimeSeriesImg"><a href="./Images/Science/NIP/TimeSeries.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/TimeSeries.png" /></a><span>Observed and Inferred time series of fraction of flooded area for all of Bangladesh for the training and testing set. This model is used for the historical time series inference (see below).</span></div><br /><br />For the testing, a single year (2018) is completely removed from the dataset.<br /><br />The result of the developed fusion model is shown here for a single day (Mai 5 2020) on all available chips for this day, and as a time series for all of Bangladesh for all dates where chips are present, as examples of inference on the testing dataset.<br /><br />The 
  var R<sup>2</sup> of 0.66 shows a good agreement between the observed and modelled data.<br /><br />The time series shows that the low water values during the dry season are well modeled, and the peaks during the monsoon and irrigation season correctly reproduced.<br /><br /><div class="ScienceInsert" id="NIPHistoricalTimeSeries"><a href="./Images/Science/NIP/HistoricalTimeSeries.mp4" rel="noopener noreferrer" target="_blank"><video autoplay="" loop="" width="100%"><source src="./Images/Science/NIP/HistoricalTimeSeries.mp4" type="video/mp4"></video></a><span>Infered historical time series of fraction of flooded area from 2001 to 2021, produced with the fusion algorithm and based on the historical MODIS data.</span></div><br /><br />This result permits us to run inference on the historical data in order to produce an estimate for 2001-2020.<br /><br /><div id="NIPResult"><div class="ScienceInsert" id="NIPYearlyMaxImg"><a href="./Images/Science/NIP/YearlyMaximum.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/YearlyMaximum.png" /></a><span>Historical yearly maxima of fraction of flooded area inferred from the trained model and run on the historical MODIS dataset. Comparison with the <a href="https://github.com/cloudtostreet/MODIS_GlobalFloodDatabase" target="_blank" rel="noopener noreferrer"> Global Flood Database algorithm (GFD)</a> and the <a href="http://www.ffwc.gov.bd/" target='_blank' rel="noopener noreferrer">Bangladesh Flood Forecasting and Warning Center (FFWC)</a> generated maps.</span></div><div class="ScienceInsert" id="NIPReturnPeriodImg"><a href="./Images/Science/NIP/ReturnPeriod.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/NIP/ReturnPeriod.png" /></a><span>Return period estimates based on the newly proposed MODIS Sentinel-1 fusion algorithm and on the GFD algorithm for the historical time series 2001-2021.</span></div></div><br />The yearly maximum of the inferred historical data is compared to another MODIS algorithm, the <a href="https://github.com/cloudtostreet/MODIS_GlobalFloodDatabase" target="_blank" rel="noopener noreferrer">Global Flood Database algorithm (GFD)</a> for the same area and period.<br /><br />The developed methods shows similar trends with GFD, but a more realistic yearly maximum according to the time series analysis above.<br /><br />This inferred data permits to construct more realistic return period estimates.</div></details><br /><br /><h4>Presentations given on the subject</h4><tt>[Poster] </tt><a href="./Images/Science/NIP/Presentations/Flood_Forecasting_Meets_Machine_Learning_Workshop_JonathanGiezendanner.pdf" rel="noopener noreferrer" target="_blank"><b>Google Flood Forecasting Meets Machine Learning Workshop </b>, <i>Jan. 2023</i> - Satellite Fusion Based Historical Inundation Estimates in Bangladesh</a><br /><br /><tt>[Talk] </tt><a href="./Images/Science/NIP/Presentations/AGU22_JonathanGiezendanner.pdf" rel="noopener noreferrer" target="_blank"><b>American Geophysical Union (AGU) </b>, <i>Dec. 2022</i> - Satellite Fusion Based Historical Inundation Estimates for Accurate Return Period Estimates in Bangladesh</a><br /><br /><tt>[Talk] </tt><a href="./Images/Science/NIP/Presentations/ESA_Living_Planet_JonathanGiezendanner.pdf" rel="noopener noreferrer" target="_blank"><b>ESA Living Planet Symposium</b>, <i>Mai. 2022</i> - Creating historical time series of satellite observed inundation for risk transfer applications in Bangladesh</a></div></div><div class="BackgroundImageSource">Background image: Sentinel-2 FCC over Sylhet, Bangladesh (May 2022)</div></div></div><div id="Pima"><div class="column"><div class="contentSection"><div class="scienceWorkContent"><h3>Flood Mapping of Monsoon events over Pima County, Az, USA</h3><div class="scienceCollaborators">Collaborators: <a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/rohitmukherjee/'>Rohit Mukherjee</a><a target='_blank'  rel='noopener noreferrer' href='https://twitter.com/hk_friedrich'>Hannah Friedrich</a><a target='_blank'  rel='noopener noreferrer' href='https://beth-tellman.github.io/'>Beth Tellman</a></div>It floods in the desert! The North American Monsoon brings intense storms and sometimes flash floods each summer. 2021 was the third wettest on record in Tucson (12.79 inches).<br /><br />Understanding where and when these floods happen can be challenging, and requires large scale monitoring.<br /><br />Can satellite images provide insights into the flood extents and water pathways? Given the revisiting periods of satellites and large cloud cover during and around monsoon flood events, using these images can be challenging.<br /><br /><details><summary><div class="summary"><div class="summaryImage"><img src="./Images/Science/Pima/Cactus.jpg" /></div><span>Monsoon clouds gather over the cactus forest in the Saguaro National Park West, Wednesday, August 10, 2016. Kelly Presnell / Arizona Daily Star </span></div><div class="summaryText">Click to Read On<br /><pre>↓ </pre></div></summary><div><br /><br />This project is done in collaboration with the Pima County Government, where we are currently assessing the utility of satellite imagery to detect floods in the desert, in particular the advantage of high frequency PlanetScope commercial data.<br /><div class="ScienceInsert leftInsert" id="PimaGEE"><a href="https://jgiezendanner.users.earthengine.app/view/pimacountyhourlyrainfallmonitoringnldas" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/Pima/RainFallApp.png" /></a><span>Google Earth Engine applet developed to visualise the daily precipitation (based on the North American Land Data Assimilation System (NLDAS)) over the different watersheds. </span></div><br /><br />Flash floods in the desert during the monsoon season recess rapidly, and capturing them with satellite images appears difficult.<br /><br /><a href="https://www.planet.com/" rel="noopener noreferrer" target="_blank">PlanetScope</a> images, with their near global and near daily images, provide an interesting product to detect the differences between consecutive images, as often only wet soil or sand remains as witness of the flood itself.<br /><br />In this context, I have developed a <a href="https://jgiezendanner.users.earthengine.app/view/pimacountyhourlyrainfallmonitoringnldas" rel="noopener noreferrer" target="_blank">Google Earth Engine Applet</a> to visualize the daily precipitation over Pima county, in an effort to aid the selection of flood events to be modelled, and hint towards their location in space (c.f. figure).<br /><br />Additionally, for another project, in collaboration with a PhD student, <a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/alex-saunders-89ab9512b/'>Alex Saunders</a>, we developed a tool to map the available satellite images around a specific date. This is particularly useful here as it allows us to select flood events where satellite imagery has a potential (c.f. figure).<br /><br /><span id="ScienceSpacing"><br /><br /><br /></span><div class="ScienceInsert"><a href="./Images/Science/Pima/SatImageAvailability.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/Pima/SatImageAvailability.png" /></a><span>Satellite image availability around a specified date for a given RoI, automatically retrieved. Built on Google Earth Engine and PlanetScope API in collaboration with <a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/alex-saunders-89ab9512b/'>Alex Saunders</a>.</span></div><br /><br />I have contributed to hand labeling flood events and developed machine learning algorithms to classify the wet sand we observed.<br /><br />One of the promising methods we developed is based on selecting two consecutive PlanetScope images, one on the morning of the event, and one on the day after.<br /><br /><div class="ScienceInsert"><a href="./Images/Science/Pima/PimaAlgo.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/Pima/PimaAlgo.png" /></a><span>FCC PlanetScope images before and after the event and initial results of the random forest algorithm along with naive NDWI thresholding. Figure Credit: <a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/rohitmukherjee/'>Rohit Mukherjee</a></span></div><br />This permits to identify the changes in the landscape, and seems to be most promising with the algorithms we developed.</div></details><br /><h4>Presentations given on the subject</h4><tt>[Poster] </tt><a href="./Images/Science/Pima/Presentations/AGU22_BethTellman.pdf" rel="noopener noreferrer" target="_blank"><b>American Geophysical Union (AGU) </b>, <i>Dec. 2022</i> - Flooding in the desert: Assessing the value of satellite observations of inundation from the North American Monsoon with the Pima County Regional Flood Control District</a></div></div><div class="BackgroundImageSource">Background image: PlanetScope multi-date NIR composite over West Tucson, Az, USA (July 31 and August 1st 2022)</div></div></div><div id="CSDAP"><div class="column"><div class="contentSection"><div class="scienceWorkContent"><h3>Public vs Commercial Satellite data: creating a high resolution flood dataset to assess their advantages</h3><div class="scienceCollaborators">Collaborators: <a target='_blank'  rel='noopener noreferrer' href='https://geography.arizona.edu/people/zhijie-zhang'>Zhijie Zhang</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/alexander-melancon-865165154/'>Alexander Melancon</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/rohitmukherjee/'>Rohit Mukherjee</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/xhagrg/'>Iksha Gurung</a><a target='_blank'  rel='noopener noreferrer' href='https://www.linkedin.com/in/matthew-purri/'>Matthew Purri</a><a target='_blank'  rel='noopener noreferrer' href='https://appliedmath.arizona.edu/person/sarah-luca'>Sarah Luca</a><a target='_blank'  rel='noopener noreferrer' href='http://www.columbia.edu/~ula2/'>Upmanu Lall</a><a target='_blank'  rel='noopener noreferrer' href='https://www2.cs.arizona.edu/~kobus/'>Kobus Barnard</a><a target='_blank'  rel='noopener noreferrer' href='https://appliedsciences.nasa.gov/about/our-team/andrew-molthan'>Andrew Molthan</a><a target='_blank'  rel='noopener noreferrer' href='https://beth-tellman.github.io/'>Beth Tellman</a></div>This project proposes to create a high-resolution dataset of flood events labelled on <a href="https://www.planet.com/" rel="noopener noreferrer" target="_blank">PlanetScope</a> imagery. The main goal of the project is to understand if publicly available data can be as effective in detecting floods as commercial data.<br /><br /><details><summary><div class="summary"><div class="summaryImage"><img src="./Images/Science/CSDAP/FloodPlanet_locations.png" /></div><span>Locations of the different labelled flood events, with their corresponding publicly available datasets. Figure credit: <a target='_blank'  rel='noopener noreferrer' href='https://geography.arizona.edu/people/zhijie-zhang'>Zhijie Zhang</a></span></div><div class="summaryText">Click to Read On<br /><pre>↓ </pre></div></summary><div><br /><br />One of the main outputs of this work is to publish a publicly available high resolution flood dataset. The selected flood events are based on existing flood event datasets (<a href="https://xview2.org/dataset" rel="noopener noreferrer" target="_blank">xBD</a>, <a href="https://github.com/cloudtostreet/Sen1Floods11" rel="noopener noreferrer" target="_blank">Sen1FLoods11</a>, <a href="https://nasa-impact.github.io/etci2021/" rel="noopener noreferrer" target="_blank">NASA IMPACT</a>, FloodPlanet (in house)), in order to be able to compare with other lower resolution datasets, but also label a few new events.<br /><br /><div class="ScienceInsert" id="CSDAPSampling"><a href="./Images/Science/CSDAP/Sampling.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/CSDAP/Sampling.png" /></a><span>Example of chip selection for a flood event: the blue dots represent where a full chip (with no missing data) is available, the colored chips then represent a first sampling meant accurately reproducing the distribution of the overall dataset, done via Latin Hypercube Sampling, the chips are then clustered based on spatial distribution via k-means (the different colors), and finally within these clusters, one chip is selected to be furthest apart from all other chips. A total of 15-20 chips per event are selected for the hand labelling process (depending on the quality of the chips).</span></div><br /><div class="ScienceInsert leftInsert" id="CSDAPLabelImage"><a href="./Images/Science/CSDAP/Labels.png" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/CSDAP/Labels.png" /></a><span>Example of two PlanetScope chips (False Color Composite (FCC)) and the hand labelled data. Figure credit: <a target='_blank'  rel='noopener noreferrer' href='https://geography.arizona.edu/people/zhijie-zhang'>Zhijie Zhang</a></span></div><br /><br /><span id="ScienceSpacing"><br /><br /><br /></span>In the context of this work, I have mainly been involved in writing a pipeline to download and process PlanetScope scenes into chips, from which we sample a representative subset which is then labelled (c.f. figure above). <br /><br />The events have been selected to coincide in time with available Harmonized Landsat Sentinel-2 (HLS) or Sentinel-1 data, such that deep learning models can be developed to compare the commercial vs public data source.<br /><br />For each event, the selected chips have been hand labelled with three classes: no water, low confidence water, high confidence water (c.f. figure).<br /><br />The data processing and labelling of all events has been completed, and we are currently working on releasing the dataset along with baseline model results (deep learning both on public and commercial data).<span id="ScienceSpacing"><br /><br /><br /><br /></span></div></details></div></div><div class="BackgroundImageSource">Background image: Selection of chips of PlanetScope False Color Composite, overlaid with flood labels for a flood event in Bolivia on Feb. 15 2018.</div></div></div></div><div id="sciencePast"><div class="column"><div class="contentSection"><h2>Past Work</h2></div></div><div id="GPNP"><div class="column"><div class="contentSection"><div class="scienceWorkContent"><h3>Spatiotemporal dynamical modelling of ground beetle presence in mountains based on Earth Observation data</h3><div class="scienceCollaborators">Collaborators: <a target='_blank'  rel='noopener noreferrer' href='https://www.unive.it/data/people/21736721'>Damiano Pasetto</a><a target='_blank'  rel='noopener noreferrer' href='https://ch.linkedin.com/in/javier-perez-saez-2275a692'>Javier Perez-Saez</a><a target='_blank'  rel='noopener noreferrer' href='https://www.researchgate.net/scientific-contributions/Cristiana-Cerrato-71730146'>Cristiana Cerrato</a><a target='_blank'  rel='noopener noreferrer' href='https://www.researchgate.net/profile/Ramona-Viterbi'>Ramona Viterbi</a><a target='_blank'  rel='noopener noreferrer' href='https://www.isac.cnr.it/en/users/silvia-terzago'>Silvia Terzago</a><a target='_blank'  rel='noopener noreferrer' href='https://www.isac.cnr.it/en/users/elisa-palazzi'>Elisa Palazzi</a><a target='_blank'  rel='noopener noreferrer' href='https://people.epfl.ch/andrea.rinaldo'>Andrea Rinaldo</a></div>Mountain areas represent a challenging environment to efficiently monitor species over extended periods of time in a large area.<br /><br />To make informed decisions, park managers in protected areas may require knowledge about the health, presence, and dynamics of species in these areas.<br /><br />To accomplish this, they may need to gain further information beyond the sampled data, extrapolating the data beyond the observed and integrating population dynamics for near-term forecasting of species presence.<br /><br /><details><summary><div class="summary"><div class="summaryImage"><img src="./Images/Science/GPNP/Framework.jpg" /></div></div><div class="summaryText">Click to Read On<br /><pre>↓ </pre></div></summary><div><br /><br />In order to accurately model these species, it is of crucial importance to understand their drivers for presence and dynamics.<br /><br /><div class="ScienceInsert leftInsert" id="GPNPSchema"><a href="./Images/Science/GPNP/schema.webp" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/GPNP/schema.webp" /></a><span>Schematic representation of the proposed framework: develop an applied metapopulation framework to reproduce observed dynamics of mountain species in space and time driven by Earth Observation and calibrated on Insitu Observations.</span></div><br /><br />The goal of this study is to develop an applied metapopulation framework to reproduce observed dynamics of mountain species in space and time, driven by Earth Observation and calibrated on Insitu Observations.<br /><br /><div class="ScienceInsert rightInsert" id="GPNPMetapopulation"><a href="./Images/Science/GPNP/metapopulation.webp" rel="noopener noreferrer" target="_blank"><img src="./Images/Science/GPNP/metapopulation.webp" /></a></div><span id="ScienceSpacing"><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /></span><br /><br />A metapopulation is commonly described as a population of populations of a single species , i.e. a population comprised of multiple subpopulations, called local populations inhabiting the same landscape, but in distinct geographical locations. The metapopulation concept is an abstraction of the concept of population, where an ensemble of interacting individuals is considered to a higher level, and where interacting subpopulations are considered.<br /><br />The specific metapopulation model used here is called Spatially-Explicit Stochastic Patch Occupancy Model (SPOM).<br /><br />Building on a grid with N cells, SPOM computes a possible distribution of occupied cells at every simulation time t by considering extinction and colonisation processes, whose rates depend on the species properties and on the landscape features. A binary state variable w<sub>i</sub> (t) is set to 1 when the cell i is occupied and 0 when empty (i = 1, ... , N).<br /><br />Starting from a given initial distribution of occupied cells, at each time step, the model allows unoccupied cells to be colonised by surrounding occupied cells with a certain probablity.<br /><br />Then, the cell becomes occupied at time t + ∆t depending on a random sample from a Bernoulli distribution. Similarly, species in occupied cells can go extinct with a certain probability. SPOM works as a Markov chain, where, for each cell, the probabilities of colonisation and extinction events are modelled depending on presence and conditions.<br /><br /><div class="ScienceInsert leftInsert" id="GPNPEOData"><a href="./Images/Science/GPNP/EOData.webm" rel="noopener noreferrer" target="_blank"><video autoplay="" loop="" width="100%"><source src="./Images/Science/GPNP/EOData.webm" type="video/webm"></video></a><span>Static and dynamic Earth Observation data used in the study to characterise the niche of the species in each pixel.</span></div><br /><br />In the context of this work, the colonisation and extinction probabilities are based on using Earth Observation data to characterise the niche of the species. <br /><br />The factors are combined in a non-linear logistic function to best describe the niche.<br /><br />The different EO factors are selected to best describe the environmental conditions relevant for the modeled species.<br /><br /><span id="ScienceSpacing"><br /><br /><br /><br /><br /><br /><br /></span>The developed framework proposes a three step algorithm:<br />1. Estimation of the initial presence of the species in the landscape through a <a href="https://en.wikipedia.org/wiki/Species_distribution_modelling" rel="noopener noreferrer" target="_blank">Species Distribution Model (SDM)</a>; <br />2. Calibration of the <a href="https://kingaa.github.io/short-course/mif/mif.html" rel="noopener noreferrer" target="_blank">partially observed markov process (POMP) through iterated filtering (IF)</a>;<br />3. Simulation of the species in the landscape with the calibrated model (inference).<br /><br /><div class="ScienceInsert" id="GPNPAlgoHolder"><div class="GPNPAlgo"><div class="GPNPAlgo1" style="top: 00%; right: 0; width: 50%; height: 25%;"></div><div class="GPNPAlgo2" style="top: 25%; right: 0; width: 50%; height: 43%;"></div><div class="GPNPAlgo3" style="top: 68%; right: 0; width: 50%; height: 32%;"></div><div id="GPNPAlgoImage"><img src="./Images/Science/GPNP/Algo/0.png" /></div></div><span><tt>[Hover over the different parts of the algorithm for more details]</tt>Details of the developed algorithm.</span></div><br /><br />The iterated filtering algorithm allows data only partially observed in time to be accommodated by solely updating the calibration at time steps where the data is available.<br /><br />This developed framework has been tested on two species of Carabids in the Gran Paradiso National Park (GPNP), where the presence has been modelled in space and time.<br /><br /><div class="ScienceInsert" id="GPNPResultHolder"><div id="GPNPResult"><a href="./Images/Science/GPNP/pterostichus_flavofemoratus.webm" rel="noopener noreferrer" target="_blank"><video autoplay="" loop="" width="100%"><source src="./Images/Science/GPNP/pterostichus_flavofemoratus.webm" type="video/webm"></video></a><a href="./Images/Science/GPNP/carabus_depressus.webm" rel="noopener noreferrer" target="_blank"><video autoplay="" loop="" width="100%"><source src="./Images/Science/GPNP/carabus_depressus.webm" type="video/webm"></video></a></div><span>Average occupancy of <tt>Pterostichus flavofemoratus</tt> and <tt>Carabus depressus</tt> over the Gran Paradiso National Park for the years 2006 to 2013, result of the dynamical metapopulation model.</span></div><br />Given the process based nature of this model, the framework has the potential to propagate the presence of a species in space and time, and potentially inform on the effects of climate change.</div></details><br /><h4>Publications</h4><tt>[PNAS] </tt><a href="https://www.pnas.org/doi/10.1073/pnas.1919580117" rel="noopener noreferrer" target="_blank"><b>Giezendanner et al.</b>, <i>2020</i> - Earth and field observations underpin metapopulation dynamics in complex landscapes: Near-term study on Carabids</a><h4>Presentations given on the subject</h4><tt>[eLightning] </tt><a href="https://agu2021fallmeeting-agu.ipostersessions.com/default.aspx?s=F4-5F-FA-F4-D2-3F-54-E9-32-96-55-2A-F6-E4-27-45&guestview=true" rel="noopener noreferrer" target="_blank"><b>American Geophysical Union (AGU) </b>, <i>Dec. 2021</i> - Earth and field observations underpin metapopulation dynamics in complex landscapes: near-term study on Carabids</a></div></div><div class="BackgroundImageSource">Background image: Modelling output of the presence of <tt>Carabus depressus</tt> for 2013 over the Gran Paradiso National Park.</div></div></div></div><div id="publications"><div class="column"><div class="contentSection"><h2>Publications</h2><div id="papers"><div class="paper" onclick="window.open('https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021WR029813')"><div class="paperTitle">A note on the role of seasonal expansions and contractions of the flowing fluvial network on metapopulation persistence</div><div class="paperInfo"><b>Giezendanner, J</b>, Benettin, P, Durighetto, N, Botter, G, Rinaldo, A<br /><i>Water Resources Research, 2021</i></div></div><div class="paper" onclick="window.open('https://www.pnas.org/doi/10.1073/pnas.1919580117')"><div class="paperTitle">Earth and field observations underpin metapopulation dynamics in complex landscapes: Near-term study on carabids</div><div class="paperInfo"><b>Giezendanner, J</b>, Pasetto, D, Perez-Saez, J, Cerrato, C, Viterbi, R, Terzago, S, Palazzi, E, Rinaldo, A<br /><i>Proceedings of the National Academy of Sciences, 2020</i></div></div><div class="paper" onclick="window.open('https://infoscience.epfl.ch/record/273932?ln=en')"><div class="paperTitle">Beyond the patch: on landscape-explicit metapopulation dynamics</div><div class="paperInfo"><b>Giezendanner, J</b><br /><i>PhD Thesis, 2020</i></div></div><div class="paper" onclick="window.open('https://www.sciencedirect.com/science/article/pii/S0022519318305848')"><div class="paperTitle">On the probabilistic nature of the species-area relation</div><div class="paperInfo">Zaoli, S, Giometto, A, <b>Giezendanner, J</b>, Maritan, A, Rinaldo, A<br /><i>Journal of Theoretical Biology, 2019</i></div></div><div class="paper" onclick="window.open('https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0213775')"><div class="paperTitle">A minimalist model of extinction and range dynamics of virtual mountain species driven by warming temperatures</div><div class="paperInfo"><b>Giezendanner, J</b>, Bertuzzo, E, Pasetto, D, Guisan, A, Rinaldo, A<br /><i>PLoS One, 2019</i></div></div><div class="paper" onclick="window.open('https://ieeexplore.ieee.org/document/7759277')"><div class="paperTitle">Towards 3-D distributed odor source localization: an extended graph-based formation control algorithm for plume tracking</div><div class="paperInfo">Soares, J M, Marjovi, A, <b>Giezendanner, J</b>, Kodiyan, A, Aguiar, A P, Pascoal, A M, Martinoli, A<br /><i>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016</i></div></div><div class="paper" onclick="window.open('https://archive.ismrm.org/2016/0022.html')"><div class="paperTitle">Automatic quality assessment of short and long-TE brain tumour MRSI data using novel Spectral Features</div><div class="paperInfo">de Barros, N P, McKinley, R, <b>Giezendanner, J</b>, Knecht, U, Wiest, R, Slotboom, J<br /><i>Proc. Intl. Soc. Mag. Reson. Med, 2016</i></div></div><div class="paper" onclick="window.open('https://infoscience.epfl.ch/record/213510?ln=en')"><div class="paperTitle">Rainfall Forecasting in Burkina Faso Using Bayesian-Wavelet Neural Networks</div><div class="paperInfo"><b>Giezendanner, J</b><br /><i>Master Thesis, 2015</i></div></div></div></div></div></div><div id="gameDev"><div class="column"><div class="contentSection"><h1>Game Development</h1><div class="EarlyCoffeeImg" onclick="window.open('https://EarlyCoffee.Games')"><img src="./Images/GameDev/EarlyCoffeeGamesLogo.png" /></div><div class="intro">Hobby game developer since 2014, I turned semi-professional in 2020 by co-founding <a href="https://EarlyCoffee.Games" rel="noopener noreferrer" target="_blank">Early Coffee Games</a>. We are currently developing <a href="https://Underwatertale.com" rel="noopener noreferrer" target="_blank">Hermit: an Underwater Tale</a>.<br /></div><h2>Backstory</h2>Game development started for me as a silly distraction and creative outlet in 2014 when Tristan Thévenoz approached me. Tristan is a classically educated artist, proficient in multiple forms of expression and passionate about the creative process. His love of video games led him to dabble in pixel art in 2013, and he was then looking for somebody to work with, on the technical aspect. This is when he approached me, and we soon became friends and started working on one silly project after the other.<br /><br />In our early days, we had the chance to get approached by an artist called <a href="https://www.francoisburland.com/" rel="noopener noreferrer" target="_blank">François Burland</a>, who was interested in hiring us to create video games for his arts installation. Over the course of three years, under the umbrella of <a href="https://sharpedstonestudios.ch" rel="noopener noreferrer" target="_blank">Sharped Stone Studios</a> , we participated in two different arts installation, each time trying to incorporate the essence of the artists' vision we were working with:<ul><li><b>SuperNova (2017)</b>, set in Martigny, a small town in the middle of the Alps in Switzerland, the exhibition focused on cultural landmarks in and around Martigny, reinterpreted by various artists. We developed <a href="https://itch.io/c/392769/supernova-martigny" rel="noopener noreferrer" target="_blank">two games</a> dedicated to the pizza places and roundabouts, both very abundant in Martigny.</li><li><b>Atomic Bazar (2018 - 2019)</b>, set in Fribourg, this exhibition was set around François' vision of the cold war. We developed <a href="https://itch.io/c/379794/atomik-bazar">four games</a>, meant to encapsulate his vision and art into games.</li></ul><h2>Early Coffee Games</h2><a href="https://EarlyCoffee.Games" rel="noopener noreferrer" target="_blank">Early Coffee Games</a> is a game development company based in Switzerland we created in 2020 with Tristan. The company is our step into semi-professional game development.<br /><br />Since its creation, the company can note a couple of successes:<ul><li>In 2020 we received the <b><a href="https://prohelvetia.ch" target="_blank"  rel="noopener noreferrer">ProHelvetia</a> pre-production grant</b> for our debut game 
 <a href='https://Underwatertale.com' target="_blank"  rel="noopener noreferrer">Hermit: an Underwater Tale</a> (see below)
 . This allowed us to hire <a href="https://www.maneingreen.com/" target="_blank"  rel="noopener noreferrer">Plume Oggier</a> for creating the game's music, <a href="https://www.linkedin.com/in/gwenbuord/" target="_blank"  rel="noopener noreferrer">Gwen Buord</a> to produce the game's sounds, as well as <a href="https://www.linkedin.com/in/jonathan-fellay-41ba01ba/" target="_blank"  rel="noopener noreferrer">Jonathan Fellay</a> for the narrative part of the adventure. <a href="https://earlycoffee.games/ChroMaticRacing/" target="_blank" rel="noopener noreferrer"><img class=rightInsert id=chromaticImage src="./Images/GameDev/chromatic.png"></a> </li><li>In 2021 the museum <a href="https://www.fr.ch/mahf/espace-jean-tinguely-niki-de-saint-phalle" target="_blank" rel="noopener noreferrer">Espace Jean-Tinguely Nicki de Saint Phalle</a> contracted us to create a unique art piece complementing their exhibition. We created <a href="https://earlycoffee.games/ChroMaticRacing/" target="_blank" rel="noopener noreferrer">Chromatic Racing</a>, an interactive piece, which invites the visitor to create a piece of art by playing the game. The piece is exposed form 2019 to 2024.</li><li>In 2022 we were selected for the Swiss delegation to go to the <a href="https://gdconf.com/" target="_blank" rel="noopener noreferrer">Games Developers Conference (GDC)</a> in San-Francisco, where we showed Hermit.</li><li>In 2022 we received a follow-up <b><a href="https://prohelvetia.ch" target="_blank"  rel="noopener noreferrer">ProHelvetia</a> production grant</b> for <a href='https://Underwatertale.com' target="_blank"  rel="noopener noreferrer">Hermit: an Underwater Tale</a>.</li></ul>The main focus of the studio is currently to develop Hermit.</div></div><div id="Hermit"><div class="column"><a href="https://Underwatertale.com" rel="noopener noreferrer" target="_blank"><div class="HermitLogo"><img src="./Images/GameDev/HermitLogo.png" /></div></a><br /><div class="HermitContent"><a href="https://Underwatertale.com" rel="noopener noreferrer" target="_blank">Hermit: an Underwater Tale</a> is currently the studio's main focus. The game is a fast paced action game with arcade elements. You play as a hermit crab who faces waves of creeps and dangerous sea creatures.<br /><br />In order to protect yourself and defeat your enemies, you will use a wide variety of empty shells as weapons. Each shell comes with a specific set of moves and attacks and will eventually break after use.<br /><br />Without any shell, the hermit is fully exposed and any damage he receives will be lethal. The game features a simple core mechanic paired with a high and ever increasing difficulty over multiple levels.<br /><br />In order to beat the game, you will have to combine skill, real-time resources management, smart item purchases, upgrade strategies and serious stamina in order to survive.<br /><br /><br /><br />Feel free to check it out and let us know what you think!</div><div class="HermitFrame"><iframe frameborder="0" height="190" src="https://store.steampowered.com/widget/1773740/" width="646"></iframe></div></div></div></div><div class="copyright">© 2022 Jonathan Giezendanner<br />Source code for this website avaialable under MIT Licence on <a href="https://github.com/GieziJo/GieziJo.github.io" rel="noopener noreferrer" target="_blank">Github</a></div></div><script>var scrollFun = function() {(window.scrollY > 350) ? navigation.classList.add("activateNavigation"):navigation.classList.remove("activateNavigation")};</script><script>window.addEventListener("scroll", scrollFun);</script><script>scrollFun();</script></body></html>